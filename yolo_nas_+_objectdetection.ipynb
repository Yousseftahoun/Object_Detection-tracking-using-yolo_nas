{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2a_vfmLFp4A",
    "outputId": "2f042f09-9597-4e0a-dfcb-4888c81307be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'DeepSORT-Object-Tracking'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AarohiSingla/DeepSORT-Object-Tracking.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErlQru0uF6_F",
    "outputId": "3cb9277f-46bf-4546-ef5c-96b048bd66c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\deep learning assignments\\test\\DeepSORT-Object-Tracking\n"
     ]
    }
   ],
   "source": [
    "%cd DeepSORT-Object-Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7_E56bDGatF",
    "outputId": "81ce3ad4-f5af-42c3-bbd1-d13071e29317"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for pycocotools (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [17 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\pycocotools\n",
      "  copying pycocotools\\coco.py -> build\\lib.win-amd64-cpython-39\\pycocotools\n",
      "  copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-cpython-39\\pycocotools\n",
      "  copying pycocotools\\mask.py -> build\\lib.win-amd64-cpython-39\\pycocotools\n",
      "  copying pycocotools\\__init__.py -> build\\lib.win-amd64-cpython-39\\pycocotools\n",
      "  running build_ext\n",
      "  C:\\Users\\HP\\AppData\\Local\\Temp\\pip-build-env-km1fthme\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: C:\\Users\\HP\\AppData\\Local\\Temp\\pip-install-l9jlrrh9\\pycocotools_3813cd65650b4a78b6a524e7fddc8e72\\pycocotools\\_mask.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  Compiling pycocotools/_mask.pyx because it changed.\n",
      "  [1/1] Cythonizing pycocotools/_mask.pyx\n",
      "  building 'pycocotools._mask' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pycocotools\n",
      "ERROR: Could not build wheels for pycocotools, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install -q super-gradients==3.1.0\n",
    "!pip install -q imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fS4KRdBHniq",
    "outputId": "31be9289-927d-4454-812c-39c5752be8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement openssl (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for openssl\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easydict\n",
      "  Downloading easydict-1.10.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: easydict\n",
      "  Building wheel for easydict (setup.py): started\n",
      "  Building wheel for easydict (setup.py): finished with status 'done'\n",
      "  Created wheel for easydict: filename=easydict-1.10-py3-none-any.whl size=6492 sha256=06b23b48439fd22f7586db273f8b6b8bbdf0bfbb4d9925e8ba9a7f1b9ba8a30f\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\0d\\9a\\a9\\02f3a5f0c6b2c57184661770360c58db8166f5c877780e98f2\n",
      "Successfully built easydict\n",
      "Installing collected packages: easydict\n",
      "Successfully installed easydict-1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "--_VIWE1GELq"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np\n",
    "from deep_sort.utils.parser import get_config\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "from deep_sort.sort.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting super_gradients\n",
      "  Using cached super_gradients-3.2.0-py3-none-any.whl (6.4 MB)\n",
      "Collecting treelib==1.6.1\n",
      "  Using cached treelib-1.6.1-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=1.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (1.9.1)\n",
      "Requirement already satisfied: opencv-python>=4.5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (4.7.0.72)\n",
      "Requirement already satisfied: pygments>=2.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (2.14.0)\n",
      "Collecting pip-tools>=6.12.1\n",
      "  Using cached pip_tools-7.3.0-py3-none-any.whl (57 kB)\n",
      "Collecting json-tricks==3.16.1\n",
      "  Using cached json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting pycocotools==2.0.6\n",
      "  Using cached pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting sphinx~=4.0.2\n",
      "  Using cached Sphinx-4.0.3-py3-none-any.whl (2.9 MB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (63.4.1)\n",
      "Collecting onnxruntime==1.13.1\n",
      "  Using cached onnxruntime-1.13.1-cp39-cp39-win_amd64.whl (5.9 MB)\n",
      "Requirement already satisfied: jsonschema>=3.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (4.16.0)\n",
      "Collecting coverage~=5.3.1\n",
      "  Using cached coverage-5.3.1-cp39-cp39-win_amd64.whl (212 kB)\n",
      "Requirement already satisfied: torch>=1.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (2.0.0.dev20230220+cpu)\n",
      "Collecting onnx-simplifier<1.0,>=0.3.6\n",
      "  Using cached onnx_simplifier-0.4.33-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Collecting onnx==1.13.0\n",
      "  Using cached onnx-1.13.0-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "Requirement already satisfied: Deprecated>=1.2.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (1.2.14)\n",
      "Collecting stringcase>=1.2.0\n",
      "  Using cached stringcase-1.2.0-py3-none-any.whl\n",
      "Collecting torchmetrics==0.8\n",
      "  Using cached torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
      "Collecting rapidfuzz\n",
      "  Using cached rapidfuzz-3.2.0-cp39-cp39-win_amd64.whl (1.8 MB)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (0.15.0.dev20230220+cpu)\n",
      "Collecting hydra-core>=1.2.0\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Collecting wheel>=0.38.0\n",
      "  Using cached wheel-0.41.2-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: boto3>=1.17.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (1.24.28)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (5.9.0)\n",
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Collecting numpy<=1.23\n",
      "  Using cached numpy-1.23.0-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (4.64.1)\n",
      "Collecting termcolor==1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting protobuf==3.20.3\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (3.5.2)\n",
      "Collecting pyparsing==2.4.5\n",
      "  Using cached pyparsing-2.4.5-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (2.11.2)\n",
      "Requirement already satisfied: pillow!=8.3,>=5.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (9.4.0)\n",
      "Requirement already satisfied: packaging>=20.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from super_gradients) (21.3)\n",
      "Collecting sphinx-rtd-theme\n",
      "  Using cached sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Collecting einops==0.3.2\n",
      "  Using cached einops-0.3.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from onnx==1.13.0->super_gradients) (4.3.0)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\hp\\anaconda3\\lib\\site-packages (from onnxruntime==1.13.1->super_gradients) (23.1.21)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from onnxruntime==1.13.1->super_gradients) (1.10.1)\n",
      "Collecting pyDeprecate==0.3.*\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\anaconda3\\lib\\site-packages (from treelib==1.6.1->super_gradients) (0.18.2)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3>=1.17.15->super_gradients) (1.27.28)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3>=1.17.15->super_gradients) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3>=1.17.15->super_gradients) (0.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Deprecated>=1.2.11->super_gradients) (1.14.1)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.2.0->super_gradients) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema>=3.2.0->super_gradients) (21.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.4->super_gradients) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.4->super_gradients) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.4->super_gradients) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.4->super_gradients) (1.4.2)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from omegaconf->super_gradients) (6.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\anaconda3\\lib\\site-packages (from onnx-simplifier<1.0,>=0.3.6->super_gradients) (13.3.1)\n",
      "Requirement already satisfied: pip>=22.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pip-tools>=6.12.1->super_gradients) (22.2.2)\n",
      "Requirement already satisfied: tomli in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pip-tools>=6.12.1->super_gradients) (2.0.1)\n",
      "Collecting build\n",
      "  Using cached build-0.10.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: click>=8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pip-tools>=6.12.1->super_gradients) (8.0.4)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (1.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (2.11.3)\n",
      "Collecting docutils<0.18,>=0.14\n",
      "  Using cached docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (1.0.3)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (2.2.0)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (2.9.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (1.1.5)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (0.7.12)\n",
      "Requirement already satisfied: imagesize in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (1.4.1)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (0.4.5)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sphinx~=4.0.2->super_gradients) (2.31.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->super_gradients) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->super_gradients) (2.16.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->super_gradients) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->super_gradients) (1.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->super_gradients) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->super_gradients) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->super_gradients) (1.51.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->super_gradients) (3.3.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.9.0->super_gradients) (3.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch>=1.9.0->super_gradients) (2.8.4)\n",
      "Collecting sphinxcontrib-jquery<5,>=4\n",
      "  Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from babel>=1.3->sphinx~=4.0.2->super_gradients) (2022.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore<1.28.0,>=1.27.28->boto3>=1.17.15->super_gradients) (1.26.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super_gradients) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super_gradients) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super_gradients) (5.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super_gradients) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->super_gradients) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from Jinja2>=2.3->sphinx~=4.0.2->super_gradients) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx~=4.0.2->super_gradients) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx~=4.0.2->super_gradients) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx~=4.0.2->super_gradients) (2.0.4)\n",
      "Collecting pyproject_hooks\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->onnx-simplifier<1.0,>=0.3.6->super_gradients) (2.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy->onnxruntime==1.13.1->super_gradients) (1.2.1)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich->onnx-simplifier<1.0,>=0.3.6->super_gradients) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->super_gradients) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->super_gradients) (3.2.2)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (pyproject.toml): started\n",
      "  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp39-cp39-win_amd64.whl size=84322 sha256=644d67a76b2e0aaf2cd47ea8e9787cdf3c086657e61f5c95f473b026d5cf8219\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\2f\\58\\25\\e78f1f766e904a9071266661d20d0bc6644df86bcd160aba11\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: termcolor, stringcase, pyreadline3, json-tricks, einops, antlr4-python3-runtime, wheel, treelib, rapidfuzz, pyproject_hooks, pyparsing, pyDeprecate, protobuf, omegaconf, numpy, humanfriendly, docutils, coverage, onnx, coloredlogs, torchmetrics, sphinx, onnxruntime, onnx-simplifier, hydra-core, build, sphinxcontrib-jquery, pycocotools, pip-tools, sphinx-rtd-theme, super_gradients\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.2.0\n",
      "    Uninstalling termcolor-2.2.0:\n",
      "      Successfully uninstalled termcolor-2.2.0\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.18.1\n",
      "    Uninstalling docutils-0.18.1:\n",
      "      Successfully uninstalled docutils-0.18.1\n",
      "  Attempting uninstall: sphinx\n",
      "    Found existing installation: Sphinx 5.0.2\n",
      "    Uninstalling Sphinx-5.0.2:\n",
      "      Successfully uninstalled Sphinx-5.0.2\n",
      "  Attempting uninstall: pycocotools\n",
      "    Found existing installation: pycocotools 2.0.7\n",
      "    Uninstalling pycocotools-2.0.7:\n",
      "      Successfully uninstalled pycocotools-2.0.7\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 build-0.10.0 coloredlogs-15.0.1 coverage-5.3.1 docutils-0.17.1 einops-0.3.2 humanfriendly-10.0 hydra-core-1.3.2 json-tricks-3.16.1 numpy-1.23.0 omegaconf-2.3.0 onnx-1.13.0 onnx-simplifier-0.4.33 onnxruntime-1.13.1 pip-tools-7.3.0 protobuf-3.20.3 pyDeprecate-0.3.2 pycocotools-2.0.6 pyparsing-2.4.5 pyproject_hooks-1.0.0 pyreadline3-3.4.1 rapidfuzz-3.2.0 sphinx-4.0.3 sphinx-rtd-theme-1.3.0 sphinxcontrib-jquery-4.1 stringcase-1.2.0 super_gradients-3.2.0 termcolor-1.1.0 torchmetrics-0.8.0 treelib-1.6.1 wheel-0.41.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "tensorflow-intel 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.23.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install super_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIrqUHZwGLV4",
    "outputId": "d4be0d8d-7453-44d9-9df0-4ddfc4452508"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-22 13:00:22] INFO - utils.py - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\deep learning assignments\\\\test'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkZn-gnsIAGV",
    "outputId": "96621d6a-1b25-4641-f822-9b53a8fcd3a6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "image_path= 'Hyundai-Grand-i10-Nios-200120231541.jpg'\n",
    "device=torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model =models.get(\"yolo_nas_s\", pretrained_weights=\"coco\").to (device)\n",
    "out =model.predict(image_path, conf=0.50)\n",
    "#out=yolo_nas_s.predict(image_path, conf-0.50).show()\n",
    "out.save(\"output.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fl33ML-WNZ6d",
    "outputId": "507b77cb-6018-49fa-97b9-bf3889ba6b6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[64.83454895019531,\n",
       "   103.5025863647461,\n",
       "   814.7365112304688,\n",
       "   476.56109619140625]],\n",
       " [0.992152750492096],\n",
       " [2.0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path='Hyundai-Grand-i10-Nios-200120231541.jpg'\n",
    "device=torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model =models.get(\"yolo_nas_l\", pretrained_weights=\"coco\").to (device)\n",
    "conf_threshold = 0.50\n",
    "detection_pred = list(model.predict(image_path, conf=conf_threshold)._images_prediction_lst)\n",
    "# Extract desired outputs\n",
    "bboxes_xyxy= detection_pred[0].prediction.bboxes_xyxy.tolist()\n",
    "confidence= detection_pred[0].prediction.confidence.tolist()\n",
    "labels= detection_pred[0].prediction.labels.tolist()\n",
    "bboxes_xyxy, confidence, labels\n",
    "#detection_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tMdkCUnNtpM",
    "outputId": "e1862362-ee5e-4bb6-c69c-e52419750b0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-22 13:01:17] INFO - feature_extractor.py - Loading weights from deep_sort/deep/checkpoint/ckpt.t7... Done!\n"
     ]
    }
   ],
   "source": [
    "deep_sort_weights ='deep_sort/deep/checkpoint/ckpt.t7'\n",
    "tracker =DeepSort(model_path=deep_sort_weights, max_age=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\deep learning assignments\\\\test\\\\DeepSORT-Object-Tracking'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fs2t1C5JRKNR",
    "outputId": "0361428f-12b9-46f1-f0e0-981a56051232"
   },
   "outputs": [],
   "source": [
    "# get the test video from the repo\n",
    "!python -m wget https://github.com/mikel-brostrom/yolo_tracking/releases/download/v.2.0/test.avi\n",
    "# extract 3 seconds worth of video frames of it\n",
    "# !yes | ffmpeg -ss 00:00:00 -i test.avi -t 00:00:02 -vf fps=30 out.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sIp5FV7OPOnM",
    "outputId": "cb0db597-0191-42af-e37f-ef0381ec1dcc"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#video_path = 'test_videos/traffic_2.mp4\"\n",
    "video_path ='test.avi'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "# Get the video properties\n",
    "frame_width= int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps =cap.get (cv2.CAP_PROP_FPS)\n",
    "#Define the codec and create Videowriter object\n",
    "fourcc =cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_path= 'output.mp4'\n",
    "#out cv2.VideoWriter(output_path, fource, fps, (640, 640)) # Updated frame size\n",
    "out= cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "frames =[]\n",
    "i=0\n",
    "counter, fps, elapsed = 0, 0, 0\n",
    "start_time= time.perf_counter()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame =cap.read()\n",
    "    if ret:\n",
    "        \n",
    "        #1280x720\n",
    "        frame=cv2.resize(frame, (1280, 720))\n",
    "        # read image and resize by half for inference\n",
    "        og_frame =cv2.cvtColor (frame, cv2.COLOR_BGR2RGB)\n",
    "        frame =og_frame.copy()\n",
    "        with torch.no_grad():\n",
    "            device=torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "            model=models.get(\"yolo_nas_l\", pretrained_weights=\"coco\").to(device)\n",
    "            onf_threshold = 0.70\n",
    "            device=0\n",
    "            detection_pred= list(model.predict (frame, conf=conf_threshold). _images_prediction_lst)\n",
    "            # Extract desired outputs\n",
    "            bboxes_xyxy =detection_pred[0].prediction.bboxes_xyxy.tolist()\n",
    "            confidence =detection_pred[0].prediction.confidence.tolist()\n",
    "            #Labels detection_pred[0].prediction. Labels.tolist()\n",
    "            labels=[label for label in detection_pred[0].prediction.labels.tolist() if label == 0]\n",
    "            class_names= ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light']\n",
    "            #Labels [Label for label in detection_pred[0].prediction. Labels.tolist() if Label == 0]\n",
    "            labels= [int (label) for label in labels] # Convert float labels to integers\n",
    "            class_name = list (set([class_names[index] for index in labels]))\n",
    "            bboxes_xywh =[]\n",
    "\n",
    "            for bbox in bboxes_xyxy:\n",
    "                x1, y1, x2, y2 = bbox\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                bbox_xywh =[x1, y1, w, h]\n",
    "                bboxes_xywh.append(bbox_xywh)\n",
    "\n",
    "            bboxes_xywh = np.array(bboxes_xywh)# Convert to Numpy array\n",
    "            tracks = tracker.update(bboxes_xywh, confidence, og_frame)\n",
    "\n",
    "            for track in tracker.tracker.tracks:\n",
    "                track_id = track.track_id\n",
    "                hits = track.hits\n",
    "                x1, y1, x2, y2 = track.to_tlbr() # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "                W = x2 - x1 # Calculate width\n",
    "                h = y2 - y1 # Calculate height\n",
    "                # Adjusting the bounding box\n",
    "                shift_percent = 0.50\n",
    "                y_shift = int(h* shift_percent)\n",
    "                x_shift = int(w* shift_percent)\n",
    "                x1 += x_shift\n",
    "                x2 += x_shift\n",
    "\n",
    "                bbox_xywh= (x1, y1, w, h) # Convert to (x, y, w, h) format\n",
    "                color= (0, 255, 0)\n",
    "                cv2.rectangle (og_frame, (int (x1), int(y1)), (int(x1+ w), int(y1 + h)), color, 2)\n",
    "                text_color= (0, 0, 0) # Black color for text\n",
    "                cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int (y1) - 5), cv2. FONT_HERSHEY_SIMPLEX, 0.5,text_color)\n",
    "                text_color= (0, 0, 0) # Black color for text\n",
    "             # update FPS and place on frame\n",
    "            current_time = time.perf_counter()\n",
    "            elapsed = (current_time - start_time)\n",
    "            counter += 1\n",
    "            if elapsed > 1:\n",
    "                fps = counter / elapsed\n",
    "                counter = 0\n",
    "                start_time = current_time\n",
    "                cv2.putText(og_frame,\n",
    "                            f\"FPS: {np.round(fps, 2)}\",\n",
    "                            (10, int (h) - 10),\n",
    "                            cv2. FONT_HERSHEY_SIMPLEX,\n",
    "                            1,\n",
    "                            (255, 255, 255),\n",
    "                            2,\n",
    "                            cv2.LINE_AA)\n",
    "\n",
    "              # append to List\n",
    "            frames.append(og_frame)\n",
    "              # write the frame to the output video file\n",
    "            out.write(cv2.cvtColor (og_frame, cv2.COLOR_RGB2BGR))\n",
    "          # show the frame\n",
    "        cv2.imshow(\"Video\",og_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord ('q'):\n",
    "              break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "av9rYfsvN0Gh"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from skimage.transform import resize\n",
    "from IPython.display import HTML\n",
    "def display_video(video):\n",
    "  fig= plt.figure (figsize=(3, 3)) #Display size specification\n",
    "  mov = []\n",
    "  for i in range (len (video)): #Append videos one by one to mov\n",
    "    img = plt.imshow(video[i], animated=True)\n",
    "    plt.axis ('off')\n",
    "    mov.append([img])\n",
    "    #Animation creation\n",
    "  anime=animation. ArtistAnimation (fig, mov, interval=50, repeat_delay=1000)\n",
    "  plt.close()\n",
    "  return anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "OdZ7NREdWGsq",
    "outputId": "ce43ed8c-c8c0-42ed-d34a-0aee10599e2f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\HP\\deep learning assignments\\test\\out.avi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10008\\3196744084.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvideo\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'out.avi'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Loading video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#video= [resize(frame, (256, 256) ) [..., :3] for frame in video] #Size adjustment (if necessary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_html5_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Inline video display in HTML5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\v2.py\u001b[0m in \u001b[0;36mmimread\u001b[1;34m(uri, format, memtest, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[0mimopen_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecypher_format_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mimopen_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"legacy_mode\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rI\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mimopen_args\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\imopen.py\u001b[0m in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_hint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat_hint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"<bytes>\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\HP\\deep learning assignments\\test\\out.avi'"
     ]
    }
   ],
   "source": [
    "video= imageio.mimread('out.avi') #Loading video\n",
    "#video= [resize(frame, (256, 256) ) [..., :3] for frame in video] #Size adjustment (if necessary)\n",
    "HTML(display_video(video).to_html5_video()) #Inline video display in HTML5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
